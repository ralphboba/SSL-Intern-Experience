# Hello! This is Eunhyuk Doo, an intern at SSL who wrote the code. I will explain how to use this code. 
# First, find the CSS selector code for the table you want, and then change the information in the parentheses on line 15 to that CSS selector code! 
# The information for both `td` and `th` will be extracted together, but if you only want either `th` or `td` information, you can modify it on line 26.

import requests
from bs4 import BeautifulSoup
from openpyxl import Workbook
import os

def get_table_data(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Select the table
    table = soup.select_one('#view02')  # You can change this
    if not table:
        print(f"Cannot find the table: {url}")
        return []  # Return an empty list if there is no data
    
    rows = table.find_all('tr')
    
    # Save the list of table data
    table_data = []
    for row in rows:
        row_data = []
        cols = row.find_all(['td', 'th']) 
        for col in cols:
            cell_data = col.get_text(strip=True)
            colspan = int(col.get('colspan', 1))
            rowspan = int(col.get('rowspan', 1))
            row_data.append((cell_data, rowspan, colspan))
        table_data.append(row_data)
    
    return table_data

def write_to_excel(table_data, start_row, ws, url):
    if not table_data:
        ws.cell(row=start_row, column=1, value="No information available")
        ws.cell(row=start_row, column=2, value=url)
        return start_row + 1
    
    max_cols = max(sum(cell[2] for cell in row) for row in table_data)
    max_rows = len(table_data)
    cell_matrix = [["" for _ in range(max_cols)] for _ in range(max_rows)]
    
    for r_idx, row in enumerate(table_data):
        c_idx = 0
        for cell in row:
            cell_value, rowspan, colspan = cell
            while c_idx < max_cols and cell_matrix[r_idx][c_idx] != "":
                c_idx += 1
            for r in range(rowspan):
                for c in range(colspan):
                    if r_idx + r < max_rows and c_idx + c < max_cols:
                        cell_matrix[r_idx + r][c_idx + c] = cell_value
            c_idx += colspan

    current_row = start_row
    for r_idx, row in enumerate(cell_matrix):
        if all(cell == "" for cell in row):  # Skip empty rows
            continue
        
        for c_idx, cell_value in enumerate(row, 3):  # Start from column C
            ws.cell(row=current_row, column=c_idx, value=cell_value)
            # Add the URL in the adjacent cell
            ws.cell(row=current_row, column=c_idx + 1, value=url)
        
        current_row += 1  # Move to the next row only if it's not an empty row
    
    return current_row  # Return the next starting row for data

# List of URLs
urls = [
    "https://oasis.kiom.re.kr/oasis/herb/monoDetailView_M05.jsp?idx=1&tab=5#view02",
    "https://oasis.kiom.re.kr/oasis/herb/monoDetailView_M05.jsp?idx=2&tab=5#view02",
    "https://oasis.kiom.re.kr/oasis/herb/monoDetailView_M05.jsp?idx=3&tab=5#view02"
]

# Create a workbook
wb = Workbook()
ws = wb.active

# Extract data from each URL and save to Excel file
start_row = 1
for i, url in enumerate(urls):
    table_data = get_table_data(url)
    start_row = write_to_excel(table_data, start_row, ws, url)

# Save the Excel file
output_file = "output1.xlsx"
wb.save(output_file)

# Automatically open the Excel file
os.system(f'start excel.exe "{output_file}"')
